{
  "metadata": {
    "id": "012",
    "slug": "crez-des-vidos-virales-ia-laide-de-nanobanana-2-pro-et-veo31-et-publiez-les-via-blotato",
    "title_en": "Create AI Viral Videos using NanoBanana 2 PRO & VEO3.1 and Publish via Blotato",
    "title_fr": "Cr√©ez des vid√©os virales IA √† l'aide de NanoBanana 2 PRO et VEO3.1 et publiez-les via Blotato",
    "description_short_en": "Effortlessly turn a Telegram message into viral AI videos with NanoBanana 2 PRO, VEO3.1 & Blotato‚Äîfully automated, multi-platform, and customizable.",
    "description_short_fr": "Transformez sans effort un message Telegram en vid√©os virales d'IA avec NanoBanana 2 PRO, VEO3.1 et Blotato, enti√®rement automatis√©s, multiplateformes et personnalisables.",
    "description_full_en": "Create AI Viral Videos using NanoBanana 2 PRO & VEO3.1 and Publish via Blotato\n1. Workflow Overview\nThis workflow automates the creation and multi-platform publishing of AI-generated viral videos using NanoBanana 2 PRO and VEO3.1, triggered by a Telegram message containing a video idea and reference image. It proceeds through three main logical blocks:\n1.1 Input Reception and Preparation:\nReceives the video idea and reference image from Telegram, retrieves and analyzes the image, and sets up master prompts and tokens.\n1.2 AI Content Generation and Media Creation:\nGenerates structured video and image prompts using OpenAI models and LangChain agents, creates an edited image with NanoBanana 2 PRO, generates a video via VEO3.1 based on the prompts and image, and prepares the final video for delivery.\n1.3 Multi-Platform Publishing and Notification:\nUploads the produced video to Blotato and publishes it to multiple social media platforms (YouTube, TikTok, Instagram, LinkedIn, Facebook, Twitter/X), followed by sending confirmation messages via Telegram.\n2. Block-by-Block Analysis\n2.1 Input Reception and Preparation\nOverview:\nThis block listens for user input on Telegram, retrieves the submitted image, analyzes it with AI to extract descriptive metadata, and prepares master prompts and tokens to be used downstream.\nNodes Involved:\nTelegram Trigger: Receive Video Idea\nSet: Bot Token (Placeholder)\nTelegram API: Get File URL\nOpenAI Vision: Analyze Reference Image\nSet Master Prompt\nNode Details:\nTelegram Trigger: Receive Video Idea\nType: Telegram Webhook Trigger\nRole: Receives incoming messages (updates) from Telegram users, including video ideas with images and captions.\nConfig: Triggers on message updates only. Uses Telegram API credentials.\nInputs: External Telegram message event.\nOutputs: Message content including caption and photo array.\nEdge Cases: Input message without photo or caption may cause downstream failures. Telegram API rate limits or connectivity issues possible.\nSet: Bot Token (Placeholder)\nType: Set node\nRole: Stores placeholders for Telegram Bot Token, FAL API key, and caption extracted from Telegram message.\nConfig: Assigns\nYOUR_BOT_TOKEN\n,\nfal_api_key\n, and\nCAPTION\nvariables.\nCAPTION\ndynamically set from Telegram message caption.\nInputs: Telegram message JSON.\nOutputs: JSON with tokens and caption for further use.\nEdge Cases: Tokens must be replaced with actual credentials; missing tokens cause API request failures.\nTelegram API: Get File URL\nType: HTTP Request\nRole: Retrieves the direct file path URL for the last photo in the Telegram message.\nConfig: Uses Telegram Bot Token to call\ngetFile\nendpoint with the file_id of the last photo in array.\nInputs: JSON with\nYOUR_BOT_TOKEN\nand Telegram message photo array.\nOutputs: JSON containing the\nfile_path\nused to access the image.\nEdge Cases: Invalid token or file_id causes API error; missing photo array causes failure.\nOpenAI Vision: Analyze Reference Image\nType: LangChain OpenAI Image Analysis node\nRole: Analyzes the retrieved reference image and outputs a YAML description with details about product or character visible in the image.\nConfig: Uses GPT-4o model, outputs YAML only, no explanation text.\nInputs: Image URL constructed from Telegram file_path and Bot Token.\nOutputs: YAML string describing color schemes, brand, outfit style, and visual description.\nEdge Cases: Image URL invalid or inaccessible; OCR/vision model misinterpretation; rate limits or timeouts.\nSet Master Prompt\nType: Set node\nRole: Defines a detailed JSON schema template called\njson_master\nfor structured video ad prompt generation.\nConfig: Contains rich schema with fields for description, style, camera, lighting, environment, motion, VFX, audio, ending, text, format, and keywords.\nInputs: Triggered after image download.\nOutputs: JSON variable\njson_master\npassed to AI prompt generator.\nEdge Cases: Misconfiguration or invalid JSON could cause parsing failures downstream.\n2.2 AI Content Generation and Media Creation\nOverview:\nThis block generates natural language prompts for image and video creation using AI agents; creates the edited image with NanoBanana 2 PRO; generates the video using VEO3.1; and prepares the outputs for publishing.\nNodes Involved:\nGenerate Image Prompt\nNanoBanana: Create Image\nWait for Image Edit\nDownload Edited Image\nAI Agent: Generate Video Script\nParse GPT Response\nOptimize Prompt for Veo\nPrepare Veo Request Body\nVeo Generation\nWait\nDownload Video\nLLM: OpenAI Chat\nLLM: Structured Output Parser\nNode Details:\nGenerate Image Prompt\nType: LangChain Agent node\nRole: Generates a concise, realistic UGC-style image prompt based on the user description (caption) and the analyzed reference image YAML.\nConfig: System prompt enforces JSON-only output with\nimage_prompt\nkey, tone casual and lifelike, max 120 words, includes camera cues and text accuracy.\nInputs: Caption from Telegram and YAML from image analysis.\nOutputs: JSON with\nimage_prompt\nstring.\nEdge Cases: AI model may misinterpret or output invalid JSON; missing inputs cause failure.\nNanoBanana: Create Image\nType: HTTP Request\nRole: Sends the generated image prompt and reference image URL to NanoBanana 2 PRO API to create an edited image (1K resolution, 9:16 aspect ratio).\nConfig: POST request with JSON body including escaped image prompt and image URLs; authorization header uses FAL API key.\nInputs: JSON from Generate Image Prompt.\nOutputs: JSON with response URL to edited image.\nEdge Cases: API downtime, invalid API key, malformed request, rate limit.\nWait for Image Edit\nType: Wait node\nRole: Pauses workflow 2 seconds to allow image processing to complete on NanoBanana server.\nConfig: Fixed 2 seconds delay.\nInputs: After NanoBanana image request.\nOutputs: Passes control downstream.\nEdge Cases: Delay may be insufficient if image processing takes longer; no error detection.\nDownload Edited Image\nType: HTTP Request\nRole: Downloads the edited image from the NanoBanana API using the response URL.\nConfig: GET request to the URL provided by NanoBanana.\nInputs: Response URL from NanoBanana.\nOutputs: JSON containing image URLs for video generation.\nEdge Cases: Network issues, invalid URL, timeout.\nAI Agent: Generate Video Script\nType: LangChain Agent node\nRole: Generates a structured JSON video prompt including\nprompt\n,\ncaption\n,\ntitle\n, and\nhashtags\nbased on the user description and image analysis content, following a detailed master schema.\nConfig: Uses GPT-4.1-mini model, with strict output constraints (valid JSON only, escaped strings).\nInputs: Master prompt JSON, user caption, and image analysis data.\nOutputs: JSON with video script content.\nEdge Cases: Model output not JSON, invalid formatting, API errors.\nParse GPT Response\nType: Code node\nRole: Parses and normalizes the AI-generated video script JSON to extract title, prompt, caption, and hashtags (array and string form), handling legacy and new formats.\nConfig: JavaScript code with robust parsing and fallback logic.\nInputs: AI Agent output JSON.\nOutputs: Clean JSON fields for downstream use.\nEdge Cases: Unexpected AI response format, JSON parse errors.\nOptimize Prompt for Veo\nType: Set node\nRole: Appends fixed cinematic style instructions and technical details (duration, aspect ratio, fps) to the video prompt for VEO3.1 compatibility.\nConfig: Adds \"consistent character throughout, photorealistic quality, professional cinematography, 8 seconds duration, 9:16 aspect ratio, 24fps\" to prompt string.\nInputs: Parsed prompt.\nOutputs:\nveo_prompt\nfield alongside other data.\nEdge Cases: Empty or invalid prompt causes issues downstream.\nPrepare Veo Request Body\nType: Code node\nRole: Constructs the JSON request body for VEO API, including the optimized prompt and the edited image URL from NanoBanana output.\nConfig: Validates presence and format of prompt and image URL before building request body with duration and aspect ratio.\nInputs:\nveo_prompt\nand edited image URL.\nOutputs: JSON with\nveo_request_body\n.\nEdge Cases: Missing prompt or image URL throws error, halting workflow.\nVeo Generation\nType: HTTP Request\nRole: Sends the video prompt and image URLs to VEO3.1 API to generate a vertical AI video (up to 8 seconds).\nConfig: POST JSON request with authorization header (FAL API key), 10-minute timeout.\nInputs: JSON\nveo_request_body\n.\nOutputs: JSON response with video URL and metadata.\nEdge Cases: API timeout, authorization error, invalid request.\nWait\nType: Wait node\nRole: Pauses 2 seconds post video generation request for processing time.\nConfig: Fixed delay.\nInputs: After video generation request.\nOutputs: Passes control downstream.\nEdge Cases: Fixed delay may not cover longer processing.\nDownload Video\nType: HTTP Request\nRole: Downloads the generated video file from the VEO response URL for local or downstream use.\nConfig: GET request, expects file response format.\nInputs: Video URL from VEO generation.\nOutputs: Binary video data and metadata.\nEdge Cases: Network issues, invalid video URL.\nLLM: OpenAI Chat\nType: LangChain OpenAI Chat node\nRole: Supports generation of intermediate text outputs (likely connected to image prompt generation).\nConfig: Uses GPT-4.1-mini model.\nInputs: Receives system message and user prompt from upstream.\nOutputs: Text response parsed by next node.\nEdge Cases: API limits, improper prompt.\nLLM: Structured Output Parser\nType: Output parser node for LangChain\nRole: Parses raw LLM output into structured JSON using example schema.\nConfig: Example schema for image prompt JSON with\nimage_prompt\nkey.\nInputs: Raw LLM chat output.\nOutputs: Parsed JSON object.\nEdge Cases: Parsing errors if output not in expected format.\n2.3 Multi-Platform Publishing and Notification\nOverview:\nThis block uploads the final AI-generated video to Blotato and publishes it automatically across multiple social platforms, followed by confirmation messages to the user on Telegram.\nNodes Involved:\nSend Video to Telegram\nUpload Video to BLOTATO\nTiktok\nLinkedin\nFacebook\nInstagram\nTwitter (X)\nYoutube\nMerge1\nSend a text message\nSticky Notes (informative)\nNode Details:\nSend Video to Telegram\nType: Telegram node\nRole: Sends the generated video back to the Telegram chat with a caption including the video URL.\nConfig: Uses Telegram credentials, sends video as binary data, dynamic chat ID from trigger.\nInputs: Binary video data from Download Video node.\nOutputs: Telegram message confirmation JSON.\nEdge Cases: Telegram API limits, video size constraints.\nUpload Video to BLOTATO\nType: Blotato node (media resource)\nRole: Uploads the downloaded video to Blotato platform for social publishing.\nConfig: Uses Blotato API credentials, mediaUrl set from downloaded video URL.\nInputs: Video URL from Download Video.\nOutputs: Media upload response with URLs.\nEdge Cases: API key invalid, upload failure, network issues.\nTiktok, Linkedin, Facebook, Instagram, Twitter (X), Youtube\nType: Blotato nodes, each for a social platform\nRole: Publishes the uploaded video media with text captions to respective platforms.\nConfig: Each node configured with platform-specific account ID, post text from parsed GPT caption, media URLs from Blotato upload, and platform-specific options (e.g., YouTube privacy set to private).\nInputs: Media URLs and captions from Upload Video to BLOTATO and Parse GPT Response nodes.\nOutputs: Posting confirmation JSON.\nEdge Cases: Platform API limits, authentication errors, content policy restrictions.\nMerge1\nType: Merge node with chooseBranch mode\nRole: Collects outputs from all social media publishing nodes to synchronize downstream confirmation.\nConfig: Awaits all 6 inputs before continuing.\nInputs: Outputs from all social platform nodes.\nOutputs: Merged data for notification.\nEdge Cases: One platform failing blocks confirmation.\nSend a text message\nType: Telegram node\nRole: Sends a simple \"Published\" confirmation message to the original Telegram chat.\nConfig: Dynamic chat ID, static text message.\nInputs: Merged node output indicating all posts done.\nOutputs: Confirmation message JSON.\nEdge Cases: Telegram API failure.\nSticky Notes\nProvide contextual labels for each major step:\nStep 1: Image creation with NanoBanana 2 PRO\nStep 2: Video generation with VEO3.1\nStep 3: Multi-platform publishing with Blotato\nOne sticky note includes documentation links and branding info.\n3. Summary Table\nNode Name\nNode Type\nFunctional Role\nInput Node(s)\nOutput Node(s)\nSticky Note\nTelegram Trigger: Receive Video Idea\nTelegram Trigger\nInput reception from Telegram\n‚Äî\nSet: Bot Token (Placeholder)\n# üìë STEP 1 ‚Äî Create Image with NanoBanana 2 PRO\nSet: Bot Token (Placeholder)\nSet\nSet API tokens and caption variable\nTelegram Trigger: Receive Video Idea\nTelegram API: Get File URL\nTelegram API: Get File URL\nHTTP Request\nGet Telegram image file URL\nSet: Bot Token (Placeholder)\nOpenAI Vision: Analyze Reference Image\nOpenAI Vision: Analyze Reference Image\nLangChain OpenAI Vision\nAnalyze image content to YAML description\nTelegram API: Get File URL\nGenerate Image Prompt\nGenerate Image Prompt\nLangChain Agent\nGenerate realistic UGC image prompt\nOpenAI Vision: Analyze Reference Image\nNanoBanana: Create Image\nNanoBanana: Create Image\nHTTP Request\nCreate edited image with NanoBanana 2 PRO\nGenerate Image Prompt\nWait for Image Edit\nWait for Image Edit\nWait\nPause for image processing\nNanoBanana: Create Image\nDownload Edited Image\nDownload Edited Image\nHTTP Request\nDownload edited image from NanoBanana\nWait for Image Edit\nSet Master Prompt\nSet Master Prompt\nSet\nDefine master prompt JSON schema\nDownload Edited Image\nAI Agent: Generate Video Script\nOpenAI Chat Model\nLangChain OpenAI Chat\nLanguage model for video script generation\nSet Master Prompt\nThink\nThink\nLangChain Tool (Think)\nAI thinking tool for intermediate processing\nOpenAI Chat Model\nAI Agent: Generate Video Script\nStructured Output Parser\nLangChain Output Parser\nParse structured AI output\nThink\nAI Agent: Generate Video Script\nAI Agent: Generate Video Script\nLangChain Agent\nGenerate structured video prompt JSON\nStructured Output Parser, OpenAI Chat Model\nParse GPT Response\nParse GPT Response\nCode\nParse and normalize video script JSON\nAI Agent: Generate Video Script\nOptimize Prompt for Veo\nOptimize Prompt for Veo\nSet\nEnhance prompt with cinematic instructions\nParse GPT Response\nPrepare Veo Request Body\nPrepare Veo Request Body\nCode\nBuild VEO3.1 API request body\nOptimize Prompt for Veo\nVeo Generation\nVeo Generation\nHTTP Request\nGenerate video from prompt and image\nPrepare Veo Request Body\nWait\nWait\nWait\nPause for video generation processing\nVeo Generation\nDownload Video\nDownload Video\nHTTP Request\nDownload generated video file\nWait\nSend Video to Telegram\nSend Video to Telegram\nTelegram\nSend generated video back to Telegram user\nDownload Video\nUpload Video to BLOTATO\nUpload Video to BLOTATO\nBlotato\nUpload video to Blotato platform\nSend Video to Telegram\nTiktok, Linkedin, Facebook, Instagram, Twitter (X), Youtube\n# üìë STEP 3 ‚Äî Publish with Blotato\nTiktok\nBlotato\nPublish video on TikTok\nUpload Video to BLOTATO\nMerge1\nLinkedin\nBlotato\nPublish video on LinkedIn\nUpload Video to BLOTATO\nMerge1\nFacebook\nBlotato\nPublish video on Facebook\nUpload Video to BLOTATO\nMerge1\nInstagram\nBlotato\nPublish video on Instagram\nUpload Video to BLOTATO\nMerge1\nTwitter (X)\nBlotato\nPublish video on Twitter (X)\nUpload Video to BLOTATO\nMerge1\nYoutube\nBlotato\nPublish video on YouTube\nUpload Video to BLOTATO\nMerge1\nMerge1\nMerge\nSynchronize multi-platform publishing output\nTiktok, Linkedin, Facebook, Instagram, Twitter (X), Youtube\nSend a text message\nSend a text message\nTelegram\nNotify Telegram user of publication completion\nMerge1\n‚Äî\nSticky Note\nSticky Note\nWorkflow step label and documentation links\n‚Äî\n‚Äî\n# üöÄ AI Viral Video Workflow ‚Äî NanoBanana 2 PRO √ó VEO3.1 √ó Blotato (By Dr. Firas)\\n\\n\n\\n\\n## üìò Documentation  \\nAccess detailed setup instructions, API config, platform connection guides, and workflow customization tips:\\n\\nüìé\nOpen the full documentation on Notion\n4. Reproducing the Workflow from Scratch\nCreate Telegram Trigger: Receive Video Idea\nNode Type: Telegram Trigger\nConfig: Listen for\nmessage\nupdates only. Use Telegram API credentials.\nPurpose: Receive user message with photo and caption.\nCreate Set node: Set Bot Token (Placeholder)\nNode Type: Set\nAssign variables:\nYOUR_BOT_TOKEN\n: your Telegram bot token (string).\nfal_api_key\n: your FAL API key (string).\nCAPTION\n: expression\n={{ $('Telegram Trigger: Receive Video Idea').item.json.message.caption }}\n.\nCreate HTTP Request: Telegram API: Get File URL\nNode Type: HTTP Request\nMethod: GET\nURL:\nhttps://api.telegram.org/bot{{ $json.YOUR_BOT_TOKEN }}/getFile?file_id={{ $('Telegram Trigger: Receive Video Idea').item.json.message.photo[ $('Telegram Trigger: Receive Video Idea').item.json.message.photo.length - 1].file_id }}\nUse credentials from Step 2.\nPurpose: Retrieve file path for last photo.\nCreate OpenAI Vision: Analyze Reference Image\nNode Type: LangChain OpenAI\nModel:\nchatgpt-4o-latest\nInput: Image URL constructed as\nhttps://api.telegram.org/file/bot{{ $json.YOUR_BOT_TOKEN }}/{{ $json.result.file_path }}\nPrompt: YAML-only analysis as per detailed specifications (product and character analysis).\nUse OpenAI credentials.\nCreate LangChain Agent: Generate Image Prompt\nNode Type: LangChain Agent\nSystem prompt: UGC Image Prompt Builder with strict JSON output for\nimage_prompt\n.\nInputs: User caption and image analysis YAML.\nOutput parser: LangChain Structured Output Parser with schema\n{ \"image_prompt\": \"string\" }\n.\nCreate HTTP Request: NanoBanana: Create Image\nNode Type: HTTP Request\nMethod: POST\nURL:\nhttps://queue.fal.run/fal-ai/nano-banana-pro/edit\nHeaders:\nContent-Type: application/json\n,\nAuthorization: Key {{ $json.fal_api_key }}\nBody: JSON including escaped\nimage_prompt\n, Telegram image URL, resolution 1K, aspect ratio 9:16, output_format png.\nCreate Wait node: Wait for Image Edit\nNode Type: Wait\nDuration: 2 seconds\nPurpose: Allow NanoBanana image processing time.\nCreate HTTP Request: Download Edited Image\nNode Type: HTTP Request\nURL: Use\nresponse_url\nfrom NanoBanana create image response.\nMethod: GET\nCreate Set node: Set Master Prompt\nNode Type: Set\nAssign variable\njson_master\nwith detailed video prompt schema JSON for video generation.\nCreate LangChain OpenAI Chat node: OpenAI Chat Model\nModel:\ngpt-4.1-mini\nPurpose: Support AI video script generation.\nCreate LangChain Tool Think node: Think\nPurpose: Intermediate AI tool step.\nCreate LangChain Output Parser: Structured Output Parser\nSchema example JSON for video prompt\n{ prompt, caption, title, hashtags }\n.\nCreate LangChain Agent: AI Agent: Generate Video Script\nUses previous nodes for input and output parsing.\nSystem prompt enforces structured video prompt generation with strict JSON output.\nCreate Code node: Parse GPT Response\nJavaScript to parse AI response to normalized fields:\ntitle\n,\nprompt\n,\ncaption\n,\nhashtags\n(array and string).\nCreate Set node: Optimize Prompt for Veo\nAppend cinematic style, duration, aspect ratio, fps to prompt string as\nveo_prompt\n.\nCreate Code node: Prepare Veo Request Body\nValidate\nveo_prompt\nand edited image URL, create JSON body for VEO API with prompt, image URLs, duration (8s), aspect ratio (9:16).\nCreate HTTP Request: Veo Generation\nMethod: POST\nURL:\nhttps://fal.run/fal-ai/veo3.1/reference-to-video\nHeaders: Authorization with FAL API key, Content-Type application/json\nBody:\nveo_request_body\nJSON\nTimeout: 600 seconds\nCreate Wait node: Wait\nDuration: 2 seconds\nPurpose: Wait for video generation processing.\nCreate HTTP Request: Download Video\nMethod: GET\nURL: Video URL from VEO response\nResponse format: file (binary)\nCreate Telegram node: Send Video to Telegram\nOperation: sendVideo\nChat ID: from original Telegram trigger message\nCaption: \"Your video is ready! üé• {{video url}}\"\nSend video as binary data.\nCreate Blotato node: Upload Video to BLOTATO\nMedia URL: from downloaded video URL\nUse Blotato API credentials.\nCreate Blotato nodes for each social platform\nPlatforms: TikTok, LinkedIn, Facebook, Instagram, Twitter (X), YouTube\nConfigure each with account IDs, post text (caption from Parse GPT Response), media URLs from upload node\nYouTube post privacy set to private, no subscriber notifications.\nCreate Merge node: Merge1\nMode: chooseBranch\nNumber inputs: 6 (one per social platform)\nPurpose: Synchronize publishing completion.\nCreate Telegram node: Send a text message\nText: \"Published\"\nChat ID: from Telegram trigger message\nTriggered after Merge1 node.\nAdd Sticky Notes\nAdd descriptive sticky notes for Steps 1, 2, 3 with color coding and documentation link as in original workflow.\n5. General Notes & Resources\nNote Content\nContext or Link\nAI Viral Video Workflow ‚Äî NanoBanana 2 PRO √ó VEO3.1 √ó Blotato by Dr. Firas\nBranding and workflow origin\nPreview video and documentation:\nYouTube Preview\nVideo preview of workflow in action\nFull setup and documentation:\nNotion Documentation\nDetailed instructions, API setup, and customization tips\nBlotato account required with Pro plan and API key\nhttps://blotato.com/?ref=firas\nEnsure ‚ÄúVerified Community Nodes‚Äù are enabled in n8n admin settings for Blotato nodes\nn8n platform configuration\nUse valid OpenAI API and Telegram Bot credentials\nAPI credentials management\nDisclaimer:\nThe provided text originates exclusively from an n8n automated workflow. It complies fully with all applicable content policies and contains no illegal, offensive, or protected content. All data handled is legal and public.\nCopied to clipboard",
    "description_full_fr": "Create AI Viral Videos using NanoBanana 2 PRO & VEO3.1 and Publish via Blotato\n1. Workflow Overview\nThis workflow automates the creation and multi-platform publishing of AI-generated viral videos using NanoBanana 2 PRO and VEO3.1, triggered by a Telegram message containing a video idea and reference image. It proceeds through three main logical blocks:\n1.1 Input Reception and Preparation:\nReceives the video idea and reference image from Telegram, retrieves and analyzes the image, and sets up master prompts and tokens.\n1.2 AI Content Generation and Media Creation:\nGenerates structured video and image prompts using OpenAI models and LangChain agents, creates an edited image with NanoBanana 2 PRO, generates a video via VEO3.1 based on the prompts and image, and prepares the final video for delivery.\n1.3 Multi-Platform Publishing and Notification:\nUploads the produced video to Blotato and publishes it to multiple social media platforms (YouTube, TikTok, Instagram, LinkedIn, Facebook, Twitter/X), followed by sending confirmation messages via Telegram.\n2. Block-by-Block Analysis\n2.1 Input Reception and Preparation\nOverview:\nThis block listens for user input on Telegram, retrieves the submitted image, analyzes it with AI to extract descriptive metadata, and prepares master prompts and tokens to be used downstream.\nNodes Involved:\nTelegram Trigger: Receive Video Idea\nSet: Bot Token (Placeholder)\nTelegram API: Get File URL\nOpenAI Vision: Analyze Reference Image\nSet Master Prompt\nNode Details:\nTelegram Trigger: Receive Video Idea\nType: Telegram Webhook Trigger\nRole: Receives incoming messages (updates) from Telegram users, including video ideas with images and captions.\nConfig: Triggers on message updates only. Uses Telegram API credentials.\nInputs: External Telegram message event.\nOutputs: Message content including caption and photo array.\nEdge Cases: Input message without photo or caption may cause downstream failures. Telegram API rate limits or connectivity issues possible.\nSet: Bot Token (Placeholder)\nType: Set node\nRole: Stores placeholders for Telegram Bot Token, FAL API key, and caption extracted from Telegram message.\nConfig: Assigns\nYOUR_BOT_TOKEN\n,\nfal_api_key\n, and\nCAPTION\nvariables.\nCAPTION\ndynamically set from Telegram message caption.\nInputs: Telegram message JSON.\nOutputs: JSON with tokens and caption for further use.\nEdge Cases: Tokens must be replaced with actual credentials; missing tokens cause API request failures.\nTelegram API: Get File URL\nType: HTTP Request\nRole: Retrieves the direct file path URL for the last photo in the Telegram message.\nConfig: Uses Telegram Bot Token to call\ngetFile\nendpoint with the file_id of the last photo in array.\nInputs: JSON with\nYOUR_BOT_TOKEN\nand Telegram message photo array.\nOutputs: JSON containing the\nfile_path\nused to access the image.\nEdge Cases: Invalid token or file_id causes API error; missing photo array causes failure.\nOpenAI Vision: Analyze Reference Image\nType: LangChain OpenAI Image Analysis node\nRole: Analyzes the retrieved reference image and outputs a YAML description with details about product or character visible in the image.\nConfig: Uses GPT-4o model, outputs YAML only, no explanation text.\nInputs: Image URL constructed from Telegram file_path and Bot Token.\nOutputs: YAML string describing color schemes, brand, outfit style, and visual description.\nEdge Cases: Image URL invalid or inaccessible; OCR/vision model misinterpretation; rate limits or timeouts.\nSet Master Prompt\nType: Set node\nRole: Defines a detailed JSON schema template called\njson_master\nfor structured video ad prompt generation.\nConfig: Contains rich schema with fields for description, style, camera, lighting, environment, motion, VFX, audio, ending, text, format, and keywords.\nInputs: Triggered after image download.\nOutputs: JSON variable\njson_master\npassed to AI prompt generator.\nEdge Cases: Misconfiguration or invalid JSON could cause parsing failures downstream.\n2.2 AI Content Generation and Media Creation\nOverview:\nThis block generates natural language prompts for image and video creation using AI agents; creates the edited image with NanoBanana 2 PRO; generates the video using VEO3.1; and prepares the outputs for publishing.\nNodes Involved:\nGenerate Image Prompt\nNanoBanana: Create Image\nWait for Image Edit\nDownload Edited Image\nAI Agent: Generate Video Script\nParse GPT Response\nOptimize Prompt for Veo\nPrepare Veo Request Body\nVeo Generation\nWait\nDownload Video\nLLM: OpenAI Chat\nLLM: Structured Output Parser\nNode Details:\nGenerate Image Prompt\nType: LangChain Agent node\nRole: Generates a concise, realistic UGC-style image prompt based on the user description (caption) and the analyzed reference image YAML.\nConfig: System prompt enforces JSON-only output with\nimage_prompt\nkey, tone casual and lifelike, max 120 words, includes camera cues and text accuracy.\nInputs: Caption from Telegram and YAML from image analysis.\nOutputs: JSON with\nimage_prompt\nstring.\nEdge Cases: AI model may misinterpret or output invalid JSON; missing inputs cause failure.\nNanoBanana: Create Image\nType: HTTP Request\nRole: Sends the generated image prompt and reference image URL to NanoBanana 2 PRO API to create an edited image (1K resolution, 9:16 aspect ratio).\nConfig: POST request with JSON body including escaped image prompt and image URLs; authorization header uses FAL API key.\nInputs: JSON from Generate Image Prompt.\nOutputs: JSON with response URL to edited image.\nEdge Cases: API downtime, invalid API key, malformed request, rate limit.\nWait for Image Edit\nType: Wait node\nRole: Pauses workflow 2 seconds to allow image processing to complete on NanoBanana server.\nConfig: Fixed 2 seconds delay.\nInputs: After NanoBanana image request.\nOutputs: Passes control downstream.\nEdge Cases: Delay may be insufficient if image processing takes longer; no error detection.\nDownload Edited Image\nType: HTTP Request\nRole: Downloads the edited image from the NanoBanana API using the response URL.\nConfig: GET request to the URL provided by NanoBanana.\nInputs: Response URL from NanoBanana.\nOutputs: JSON containing image URLs for video generation.\nEdge Cases: Network issues, invalid URL, timeout.\nAI Agent: Generate Video Script\nType: LangChain Agent node\nRole: Generates a structured JSON video prompt including\nprompt\n,\ncaption\n,\ntitle\n, and\nhashtags\nbased on the user description and image analysis content, following a detailed master schema.\nConfig: Uses GPT-4.1-mini model, with strict output constraints (valid JSON only, escaped strings).\nInputs: Master prompt JSON, user caption, and image analysis data.\nOutputs: JSON with video script content.\nEdge Cases: Model output not JSON, invalid formatting, API errors.\nParse GPT Response\nType: Code node\nRole: Parses and normalizes the AI-generated video script JSON to extract title, prompt, caption, and hashtags (array and string form), handling legacy and new formats.\nConfig: JavaScript code with robust parsing and fallback logic.\nInputs: AI Agent output JSON.\nOutputs: Clean JSON fields for downstream use.\nEdge Cases: Unexpected AI response format, JSON parse errors.\nOptimize Prompt for Veo\nType: Set node\nRole: Appends fixed cinematic style instructions and technical details (duration, aspect ratio, fps) to the video prompt for VEO3.1 compatibility.\nConfig: Adds \"consistent character throughout, photorealistic quality, professional cinematography, 8 seconds duration, 9:16 aspect ratio, 24fps\" to prompt string.\nInputs: Parsed prompt.\nOutputs:\nveo_prompt\nfield alongside other data.\nEdge Cases: Empty or invalid prompt causes issues downstream.\nPrepare Veo Request Body\nType: Code node\nRole: Constructs the JSON request body for VEO API, including the optimized prompt and the edited image URL from NanoBanana output.\nConfig: Validates presence and format of prompt and image URL before building request body with duration and aspect ratio.\nInputs:\nveo_prompt\nand edited image URL.\nOutputs: JSON with\nveo_request_body\n.\nEdge Cases: Missing prompt or image URL throws error, halting workflow.\nVeo Generation\nType: HTTP Request\nRole: Sends the video prompt and image URLs to VEO3.1 API to generate a vertical AI video (up to 8 seconds).\nConfig: POST JSON request with authorization header (FAL API key), 10-minute timeout.\nInputs: JSON\nveo_request_body\n.\nOutputs: JSON response with video URL and metadata.\nEdge Cases: API timeout, authorization error, invalid request.\nWait\nType: Wait node\nRole: Pauses 2 seconds post video generation request for processing time.\nConfig: Fixed delay.\nInputs: After video generation request.\nOutputs: Passes control downstream.\nEdge Cases: Fixed delay may not cover longer processing.\nDownload Video\nType: HTTP Request\nRole: Downloads the generated video file from the VEO response URL for local or downstream use.\nConfig: GET request, expects file response format.\nInputs: Video URL from VEO generation.\nOutputs: Binary video data and metadata.\nEdge Cases: Network issues, invalid video URL.\nLLM: OpenAI Chat\nType: LangChain OpenAI Chat node\nRole: Supports generation of intermediate text outputs (likely connected to image prompt generation).\nConfig: Uses GPT-4.1-mini model.\nInputs: Receives system message and user prompt from upstream.\nOutputs: Text response parsed by next node.\nEdge Cases: API limits, improper prompt.\nLLM: Structured Output Parser\nType: Output parser node for LangChain\nRole: Parses raw LLM output into structured JSON using example schema.\nConfig: Example schema for image prompt JSON with\nimage_prompt\nkey.\nInputs: Raw LLM chat output.\nOutputs: Parsed JSON object.\nEdge Cases: Parsing errors if output not in expected format.\n2.3 Multi-Platform Publishing and Notification\nOverview:\nThis block uploads the final AI-generated video to Blotato and publishes it automatically across multiple social platforms, followed by confirmation messages to the user on Telegram.\nNodes Involved:\nSend Video to Telegram\nUpload Video to BLOTATO\nTiktok\nLinkedin\nFacebook\nInstagram\nTwitter (X)\nYoutube\nMerge1\nSend a text message\nSticky Notes (informative)\nNode Details:\nSend Video to Telegram\nType: Telegram node\nRole: Sends the generated video back to the Telegram chat with a caption including the video URL.\nConfig: Uses Telegram credentials, sends video as binary data, dynamic chat ID from trigger.\nInputs: Binary video data from Download Video node.\nOutputs: Telegram message confirmation JSON.\nEdge Cases: Telegram API limits, video size constraints.\nUpload Video to BLOTATO\nType: Blotato node (media resource)\nRole: Uploads the downloaded video to Blotato platform for social publishing.\nConfig: Uses Blotato API credentials, mediaUrl set from downloaded video URL.\nInputs: Video URL from Download Video.\nOutputs: Media upload response with URLs.\nEdge Cases: API key invalid, upload failure, network issues.\nTiktok, Linkedin, Facebook, Instagram, Twitter (X), Youtube\nType: Blotato nodes, each for a social platform\nRole: Publishes the uploaded video media with text captions to respective platforms.\nConfig: Each node configured with platform-specific account ID, post text from parsed GPT caption, media URLs from Blotato upload, and platform-specific options (e.g., YouTube privacy set to private).\nInputs: Media URLs and captions from Upload Video to BLOTATO and Parse GPT Response nodes.\nOutputs: Posting confirmation JSON.\nEdge Cases: Platform API limits, authentication errors, content policy restrictions.\nMerge1\nType: Merge node with chooseBranch mode\nRole: Collects outputs from all social media publishing nodes to synchronize downstream confirmation.\nConfig: Awaits all 6 inputs before continuing.\nInputs: Outputs from all social platform nodes.\nOutputs: Merged data for notification.\nEdge Cases: One platform failing blocks confirmation.\nSend a text message\nType: Telegram node\nRole: Sends a simple \"Published\" confirmation message to the original Telegram chat.\nConfig: Dynamic chat ID, static text message.\nInputs: Merged node output indicating all posts done.\nOutputs: Confirmation message JSON.\nEdge Cases: Telegram API failure.\nSticky Notes\nProvide contextual labels for each major step:\nStep 1: Image creation with NanoBanana 2 PRO\nStep 2: Video generation with VEO3.1\nStep 3: Multi-platform publishing with Blotato\nOne sticky note includes documentation links and branding info.\n3. Summary Table\nNode Name\nNode Type\nFunctional Role\nInput Node(s)\nOutput Node(s)\nSticky Note\nTelegram Trigger: Receive Video Idea\nTelegram Trigger\nInput reception from Telegram\n‚Äî\nSet: Bot Token (Placeholder)\n# üìë STEP 1 ‚Äî Create Image with NanoBanana 2 PRO\nSet: Bot Token (Placeholder)\nSet\nSet API tokens and caption variable\nTelegram Trigger: Receive Video Idea\nTelegram API: Get File URL\nTelegram API: Get File URL\nHTTP Request\nGet Telegram image file URL\nSet: Bot Token (Placeholder)\nOpenAI Vision: Analyze Reference Image\nOpenAI Vision: Analyze Reference Image\nLangChain OpenAI Vision\nAnalyze image content to YAML description\nTelegram API: Get File URL\nGenerate Image Prompt\nGenerate Image Prompt\nLangChain Agent\nGenerate realistic UGC image prompt\nOpenAI Vision: Analyze Reference Image\nNanoBanana: Create Image\nNanoBanana: Create Image\nHTTP Request\nCreate edited image with NanoBanana 2 PRO\nGenerate Image Prompt\nWait for Image Edit\nWait for Image Edit\nWait\nPause for image processing\nNanoBanana: Create Image\nDownload Edited Image\nDownload Edited Image\nHTTP Request\nDownload edited image from NanoBanana\nWait for Image Edit\nSet Master Prompt\nSet Master Prompt\nSet\nDefine master prompt JSON schema\nDownload Edited Image\nAI Agent: Generate Video Script\nOpenAI Chat Model\nLangChain OpenAI Chat\nLanguage model for video script generation\nSet Master Prompt\nThink\nThink\nLangChain Tool (Think)\nAI thinking tool for intermediate processing\nOpenAI Chat Model\nAI Agent: Generate Video Script\nStructured Output Parser\nLangChain Output Parser\nParse structured AI output\nThink\nAI Agent: Generate Video Script\nAI Agent: Generate Video Script\nLangChain Agent\nGenerate structured video prompt JSON\nStructured Output Parser, OpenAI Chat Model\nParse GPT Response\nParse GPT Response\nCode\nParse and normalize video script JSON\nAI Agent: Generate Video Script\nOptimize Prompt for Veo\nOptimize Prompt for Veo\nSet\nEnhance prompt with cinematic instructions\nParse GPT Response\nPrepare Veo Request Body\nPrepare Veo Request Body\nCode\nBuild VEO3.1 API request body\nOptimize Prompt for Veo\nVeo Generation\nVeo Generation\nHTTP Request\nGenerate video from prompt and image\nPrepare Veo Request Body\nWait\nWait\nWait\nPause for video generation processing\nVeo Generation\nDownload Video\nDownload Video\nHTTP Request\nDownload generated video file\nWait\nSend Video to Telegram\nSend Video to Telegram\nTelegram\nSend generated video back to Telegram user\nDownload Video\nUpload Video to BLOTATO\nUpload Video to BLOTATO\nBlotato\nUpload video to Blotato platform\nSend Video to Telegram\nTiktok, Linkedin, Facebook, Instagram, Twitter (X), Youtube\n# üìë STEP 3 ‚Äî Publish with Blotato\nTiktok\nBlotato\nPublish video on TikTok\nUpload Video to BLOTATO\nMerge1\nLinkedin\nBlotato\nPublish video on LinkedIn\nUpload Video to BLOTATO\nMerge1\nFacebook\nBlotato\nPublish video on Facebook\nUpload Video to BLOTATO\nMerge1\nInstagram\nBlotato\nPublish video on Instagram\nUpload Video to BLOTATO\nMerge1\nTwitter (X)\nBlotato\nPublish video on Twitter (X)\nUpload Video to BLOTATO\nMerge1\nYoutube\nBlotato\nPublish video on YouTube\nUpload Video to BLOTATO\nMerge1\nMerge1\nMerge\nSynchronize multi-platform publishing output\nTiktok, Linkedin, Facebook, Instagram, Twitter (X), Youtube\nSend a text message\nSend a text message\nTelegram\nNotify Telegram user of publication completion\nMerge1\n‚Äî\nSticky Note\nSticky Note\nWorkflow step label and documentation links\n‚Äî\n‚Äî\n# üöÄ AI Viral Video Workflow ‚Äî NanoBanana 2 PRO √ó VEO3.1 √ó Blotato (By Dr. Firas)\\n\\n\n\\n\\n## üìò Documentation  \\nAccess detailed setup instructions, API config, platform connection guides, and workflow customization tips:\\n\\nüìé\nOpen the full documentation on Notion\n4. Reproducing the Workflow from Scratch\nCreate Telegram Trigger: Receive Video Idea\nNode Type: Telegram Trigger\nConfig: Listen for\nmessage\nupdates only. Use Telegram API credentials.\nPurpose: Receive user message with photo and caption.\nCreate Set node: Set Bot Token (Placeholder)\nNode Type: Set\nAssign variables:\nYOUR_BOT_TOKEN\n: your Telegram bot token (string).\nfal_api_key\n: your FAL API key (string).\nCAPTION\n: expression\n={{ $('Telegram Trigger: Receive Video Idea').item.json.message.caption }}\n.\nCreate HTTP Request: Telegram API: Get File URL\nNode Type: HTTP Request\nMethod: GET\nURL:\nhttps://api.telegram.org/bot{{ $json.YOUR_BOT_TOKEN }}/getFile?file_id={{ $('Telegram Trigger: Receive Video Idea').item.json.message.photo[ $('Telegram Trigger: Receive Video Idea').item.json.message.photo.length - 1].file_id }}\nUse credentials from Step 2.\nPurpose: Retrieve file path for last photo.\nCreate OpenAI Vision: Analyze Reference Image\nNode Type: LangChain OpenAI\nModel:\nchatgpt-4o-latest\nInput: Image URL constructed as\nhttps://api.telegram.org/file/bot{{ $json.YOUR_BOT_TOKEN }}/{{ $json.result.file_path }}\nPrompt: YAML-only analysis as per detailed specifications (product and character analysis).\nUse OpenAI credentials.\nCreate LangChain Agent: Generate Image Prompt\nNode Type: LangChain Agent\nSystem prompt: UGC Image Prompt Builder with strict JSON output for\nimage_prompt\n.\nInputs: User caption and image analysis YAML.\nOutput parser: LangChain Structured Output Parser with schema\n{ \"image_prompt\": \"string\" }\n.\nCreate HTTP Request: NanoBanana: Create Image\nNode Type: HTTP Request\nMethod: POST\nURL:\nhttps://queue.fal.run/fal-ai/nano-banana-pro/edit\nHeaders:\nContent-Type: application/json\n,\nAuthorization: Key {{ $json.fal_api_key }}\nBody: JSON including escaped\nimage_prompt\n, Telegram image URL, resolution 1K, aspect ratio 9:16, output_format png.\nCreate Wait node: Wait for Image Edit\nNode Type: Wait\nDuration: 2 seconds\nPurpose: Allow NanoBanana image processing time.\nCreate HTTP Request: Download Edited Image\nNode Type: HTTP Request\nURL: Use\nresponse_url\nfrom NanoBanana create image response.\nMethod: GET\nCreate Set node: Set Master Prompt\nNode Type: Set\nAssign variable\njson_master\nwith detailed video prompt schema JSON for video generation.\nCreate LangChain OpenAI Chat node: OpenAI Chat Model\nModel:\ngpt-4.1-mini\nPurpose: Support AI video script generation.\nCreate LangChain Tool Think node: Think\nPurpose: Intermediate AI tool step.\nCreate LangChain Output Parser: Structured Output Parser\nSchema example JSON for video prompt\n{ prompt, caption, title, hashtags }\n.\nCreate LangChain Agent: AI Agent: Generate Video Script\nUses previous nodes for input and output parsing.\nSystem prompt enforces structured video prompt generation with strict JSON output.\nCreate Code node: Parse GPT Response\nJavaScript to parse AI response to normalized fields:\ntitle\n,\nprompt\n,\ncaption\n,\nhashtags\n(array and string).\nCreate Set node: Optimize Prompt for Veo\nAppend cinematic style, duration, aspect ratio, fps to prompt string as\nveo_prompt\n.\nCreate Code node: Prepare Veo Request Body\nValidate\nveo_prompt\nand edited image URL, create JSON body for VEO API with prompt, image URLs, duration (8s), aspect ratio (9:16).\nCreate HTTP Request: Veo Generation\nMethod: POST\nURL:\nhttps://fal.run/fal-ai/veo3.1/reference-to-video\nHeaders: Authorization with FAL API key, Content-Type application/json\nBody:\nveo_request_body\nJSON\nTimeout: 600 seconds\nCreate Wait node: Wait\nDuration: 2 seconds\nPurpose: Wait for video generation processing.\nCreate HTTP Request: Download Video\nMethod: GET\nURL: Video URL from VEO response\nResponse format: file (binary)\nCreate Telegram node: Send Video to Telegram\nOperation: sendVideo\nChat ID: from original Telegram trigger message\nCaption: \"Your video is ready! üé• {{video url}}\"\nSend video as binary data.\nCreate Blotato node: Upload Video to BLOTATO\nMedia URL: from downloaded video URL\nUse Blotato API credentials.\nCreate Blotato nodes for each social platform\nPlatforms: TikTok, LinkedIn, Facebook, Instagram, Twitter (X), YouTube\nConfigure each with account IDs, post text (caption from Parse GPT Response), media URLs from upload node\nYouTube post privacy set to private, no subscriber notifications.\nCreate Merge node: Merge1\nMode: chooseBranch\nNumber inputs: 6 (one per social platform)\nPurpose: Synchronize publishing completion.\nCreate Telegram node: Send a text message\nText: \"Published\"\nChat ID: from Telegram trigger message\nTriggered after Merge1 node.\nAdd Sticky Notes\nAdd descriptive sticky notes for Steps 1, 2, 3 with color coding and documentation link as in original workflow.\n5. General Notes & Resources\nNote Content\nContext or Link\nAI Viral Video Workflow ‚Äî NanoBanana 2 PRO √ó VEO3.1 √ó Blotato by Dr. Firas\nBranding and workflow origin\nPreview video and documentation:\nYouTube Preview\nVideo preview of workflow in action\nFull setup and documentation:\nNotion Documentation\nDetailed instructions, API setup, and customization tips\nBlotato account required with Pro plan and API key\nhttps://blotato.com/?ref=firas\nEnsure ‚ÄúVerified Community Nodes‚Äù are enabled in n8n admin settings for Blotato nodes\nn8n platform configuration\nUse valid OpenAI API and Telegram Bot credentials\nAPI credentials management\nDisclaimer:\nThe provided text originates exclusively from an n8n automated workflow. It complies fully with all applicable content policies and contains no illegal, offensive, or protected content. All data handled is legal and public.\nCopied to clipboard\n\n",
    "category": "AI",
    "complexity": "Intermediate",
    "tags_en": [],
    "tags_fr": [],
    "author": "Dr. Firas",
    "date": "Unknown",
    "url_original": "https://n8nworkflows.xyz/workflows/create-ai-viral-videos-using-nanobanana-2-pro-veo31-and-publish-via-blotato-11204",
    "nodes_count": 35
  },
  "workflow_json": {
    "id": "c1RYY5JDniAWe4Lm",
    "meta": {
      "instanceId": "de822f81f3a2367cef7d9549771a77783236bc9596481be2ae65c05fbcc4b4fd",
      "templateCredsSetupCompleted": true
    },
    "name": "üí• Create AI Viral Videos using NanoBanana 2 PRO & VEO3.1 and Publish via Blotato -vide",
    "tags": [],
    "nodes": [
      {
        "id": "7c727b4c-0395-4262-85f9-b00fa9d5aa9e",
        "name": "OpenAI Chat Model",
        "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
        "position": [
          928,
          832
        ],
        "parameters": {
          "model": {
            "__rl": true,
            "mode": "list",
            "value": "gpt-4.1-mini"
          },
          "options": {}
        },
        "credentials": {
          "openAiApi": {
            "id": "HUbsD20wv3CFr7gN",
            "name": "OpenAi account"
          }
        },
        "typeVersion": 1.2
      },
      {
        "id": "913750ef-1d67-4a69-ab6d-8219b44a54ec",
        "name": "Think",
        "type": "@n8n/n8n-nodes-langchain.toolThink",
        "position": [
          1072,
          832
        ],
        "parameters": {},
        "typeVersion": 1
      },
      {
        "id": "0f440371-db4d-4847-a104-5bd02f5ec495",
        "name": "Structured Output Parser",
        "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
        "position": [
          1200,
          832
        ],
        "parameters": {
          "jsonSchemaExample": "{\n  \"prompt\": \"string\",\n  \"caption\": \"string\",\n  \"title\": \"string\", \n  \"hashtags\": \"string\"\n}\n"
        },
        "typeVersion": 1.3
      },
      {
        "id": "b5174475-5425-49de-97fa-381e573f260f",
        "name": "Telegram Trigger: Receive Video Idea",
        "type": "n8n-nodes-base.telegramTrigger",
        "position": [
          784,
          192
        ],
        "webhookId": "83b8d6e3-67b7-40f0-ba8c-b980fdcbe527",
        "parameters": {
          "updates": [
            "message"
          ],
          "additionalFields": {}
        },
        "credentials": {
          "telegramApi": {
            "id": "TBPespUzbkdn7hk7",
            "name": "Telegram_wan"
          }
        },
        "typeVersion": 1.2
      },
      {
        "id": "c52b61fe-df02-4c7f-9b1d-c8763d081c0f",
        "name": "Set Master Prompt",
        "type": "n8n-nodes-base.set",
        "position": [
          800,
          640
        ],
        "parameters": {
          "options": {},
          "assignments": {
            "assignments": [
              {
                "id": "cc2e0500-57b1-4615-82cb-1c950e5f2ec4",
                "name": "json_master",
                "type": "string",
                "value": "={\n  \"description\": \"Brief narrative description of the scene, focusing on key visual storytelling and product transformation.\",\n  \"style\": \"cinematic | photorealistic | stylized | gritty | elegant\",\n  \"camera\": {\n    \"type\": \"fixed | dolly | Steadicam | crane combo\",\n    \"movement\": \"describe any camera moves like slow push-in, pan, orbit\",\n    \"lens\": \"optional lens type or focal length for cinematic effect\"\n  },\n  \"lighting\": {\n    \"type\": \"natural | dramatic | high-contrast\",\n    \"sources\": \"key lighting sources (sunset, halogen, ambient glow...)\",\n    \"FX\": \"optional VFX elements like fog, reflections, flares\"\n  },\n  \"environment\": {\n    \"location\": \"describe location or room (kitchen, desert, basketball court...)\",\n    \"set_pieces\": [\n      \"list of key background or prop elements\",\n      \"e.g. hardwood floors, chain-link fence, velvet surface\"\n    ],\n    \"mood\": \"describe the ambient atmosphere (moody, clean, epic...)\"\n  },\n  \"elements\": [\n    \"main physical items involved (product box, accessories, vehicles...)\",\n    \"include brand visibility (logos, packaging, texture...)\"\n  ],\n  \"subject\": {\n    \"character\": {\n      \"description\": \"optional ‚Äì physical description, outfit\",\n      \"pose\": \"optional ‚Äì position or gesture\",\n      \"lip_sync_line\": \"optional ‚Äì spoken line if there‚Äôs a voiceover\"\n    },\n    \"product\": {\n      \"brand\": \"Brand name\",\n      \"model\": \"Product model or name\",\n      \"action\": \"description of product transformation or assembly\"\n    }\n  },\n  \"motion\": {\n    \"type\": \"e.g. transformation, explosion, vortex\",\n    \"details\": \"step-by-step visual flow of how elements move or evolve\"\n  },\n  \"VFX\": {\n    \"transformation\": \"optional ‚Äì describe style (neon trails, motion blur...)\",\n    \"impact\": \"optional ‚Äì e.g. shockwave, glow, distortion\",\n    \"particles\": \"optional ‚Äì embers, sparks, thread strands...\",\n    \"environment\": \"optional ‚Äì VFX affecting the scene (ripples, wind...)\"\n  },\n  \"audio\": {\n    \"music\": \"optional ‚Äì cinematic score, trap beat, ambient tone\",\n    \"sfx\": [\n      \"list of sound effects (zip, pop, woosh...)\"\n    ],\n    \"ambience\": \"optional ‚Äì background soundscape (traffic, wind...)\",\n    \"voiceover\": {\n      \"delivery\": \"tone and style (confident, whisper, deep...)\",\n      \"line\": \"text spoken if applicable\"\n    }\n  },\n  \"ending\": \"Final shot description ‚Äì what is seen or felt at the end (freeze frame, logo pulse, glow...)\",\n  \"text\": \"none | overlay | tagline | logo pulse at end only\",\n  \"format\": \"16:9 | 4k | vertical\",\n  \"keywords\": [\n    \"brand\",\n    \"scene style\",\n    \"motion type\",\n    \"camera style\",\n    \"sound mood\",\n    \"target theme\"\n  ]\n}\n"
              }
            ]
          }
        },
        "typeVersion": 3.4
      },
      {
        "id": "8d368aed-2dd7-47c2-90e8-bd9d8163ab4a",
        "name": "AI Agent: Generate Video Script",
        "type": "@n8n/n8n-nodes-langchain.agent",
        "position": [
          1008,
          640
        ],
        "parameters": {
          "text": "=Cr√©ez une invite vid√©o de style UGC en utilisant √† la fois l'image de r√©f√©rence et la description de l'utilisateur.  \n\n**Entr√©e**  \n- Description de l'utilisateur (facultatif)¬†:  \n  `{{ $('Telegram Trigger¬†: recevoir une id√©e vid√©o').item.json.message.caption }}`  \n- Analyse d'images de r√©f√©rence (rester strictement fid√®le √† ce qui est visible) :  \n  `{{ $('OpenAI Vision¬†: Analyser l'image de r√©f√©rence').item.json.content }}`  \n\n**R√®gles**  \n- Gardez le style d√©contract√©, authentique et r√©aliste. √âvitez le langage de type studio ou cin√©matographique.  \n- Mod√®le par d√©faut¬†: `veo3.1` (sauf indication contraire).  \n- Afficher uniquement **un objet JSON** avec la cl√©¬†: `video_prompt`.",
          "options": {
            "systemMessage": "=system_prompt:\n  ## SYSTEM PROMPT: Structured Video Ad Prompt Generator\n  A - Ask:\n    Generate a structured video ad prompt for cinematic generation, strictly based on the master schema provided in: {{ $json.json_master }}.\n    The final result must be a JSON object with exactly 3 top-level keys: `prompt`, `caption`, `title` and `hashtags`.\n\n  G - Guidance:\n    role: Creative Director\n    output_count: 1\n    character_limit: None\n    constraints:\n      - The output must be valid JSON.\n      - The `prompt` field must contain a **single-line JSON string** that follows the exact structure of {{ $json.json_master }} with all fields preserved.\n      - The `hashtags` field must contain array of 8-10 tags.\n      - The `caption` field should contain a short, descriptive and unique title (max 15 words).\n      - The `title` field should contain a short title.\n      - Do not include any explanations, markdown, or extra text ‚Äî only the JSON object.\n      - Escape all inner quotes in the `prompt` string so it is valid as a stringified JSON inside another JSON.\n    tool_usage:\n      - Ensure consistent alignment across all fields (camera, lighting, motion, etc.).\n      - Maintain full structure even for optional fields (use \"none\", \"\", or [] as needed).\n\n  N - Notation:\n    format: JSON\n    expected_output:\n      {\n        \"prompt\": \"{...stringified JSON of the full prompt...}\",\n        \"caption\": \"A unique short descriptive\",\n        \"title\": \"A unique short title\",\n        \"hashtags\": \"tags\"\n      }\n\n    Return JSON with: prompt (150-200 word cinematic Veo 3.1 description), caption (50-100 word social media text with emojis), hashtags (array of 8-10 tags)"
          },
          "promptType": "define",
          "hasOutputParser": true
        },
        "typeVersion": 2
      },
      {
        "id": "508e2f17-37eb-455d-b69a-19e773705e75",
        "name": "Sticky Note2",
        "type": "n8n-nodes-base.stickyNote",
        "disabled": true,
        "position": [
          720,
          544
        ],
        "parameters": {
          "color": 7,
          "width": 1852,
          "height": 428,
          "content": "# üìë STEP 2 ‚Äî Generate Video with VEO3.1"
        },
        "typeVersion": 1
      },
      {
        "id": "3d5fe2a9-6fee-4f29-a7b0-ff1628d1d96a",
        "name": "Sticky Note",
        "type": "n8n-nodes-base.stickyNote",
        "position": [
          720,
          96
        ],
        "parameters": {
          "color": 7,
          "width": 1856,
          "height": 432,
          "content": "# üìë STEP 1 ‚Äî Create Image with NanoBanana 2 PRO\n"
        },
        "typeVersion": 1
      },
      {
        "id": "3028553a-e742-49fd-b68c-6f5a9c6e0f9e",
        "name": "Set: Bot Token (Placeholder)",
        "type": "n8n-nodes-base.set",
        "position": [
          992,
          192
        ],
        "parameters": {
          "options": {},
          "assignments": {
            "assignments": [
              {
                "id": "af62651a-3fc8-419d-908b-6514f6f4bcb3",
                "name": "YOUR_BOT_TOKEN",
                "type": "string",
                "value": "YOUR_BOT_TOKEN"
              },
              {
                "id": "588b2c82-50af-41f1-bce2-0f7e627162b0",
                "name": "fal_api_key",
                "type": "string",
                "value": "YOUR_fal_api_key"
              },
              {
                "id": "bdb28513-38da-4a61-bffd-aa0f8a165579",
                "name": "CAPTION",
                "type": "string",
                "value": "={{ $('Telegram Trigger: Receive Video Idea').item.json.message.caption }}"
              }
            ]
          }
        },
        "typeVersion": 3.4
      },
      {
        "id": "ac849dab-7a31-4eed-82c6-210f312c53d0",
        "name": "Telegram API: Get File URL",
        "type": "n8n-nodes-base.httpRequest",
        "position": [
          1216,
          192
        ],
        "parameters": {
          "url": "=https://api.telegram.org/bot{{ $json.YOUR_BOT_TOKEN }}/getFile?file_id={{ $('Telegram Trigger: Receive Video Idea').item.json.message.photo[ $('Telegram Trigger: Receive Video Idea').item.json.message.photo.length - 1].file_id }}",
          "options": {}
        },
        "typeVersion": 4.2
      },
      {
        "id": "0fb7dee2-9d26-4488-b123-a68d374da7e2",
        "name": "OpenAI Vision: Analyze Reference Image",
        "type": "@n8n/n8n-nodes-langchain.openAi",
        "position": [
          1424,
          192
        ],
        "parameters": {
          "text": "=Vous √™tes assistant d'analyse d'images.\n\nVotre t√¢che consiste √† analyser l'image donn√©e et les r√©sultats de sortie **uniquement au format YAML**. N'ajoutez pas d'explications, de commentaires ou de texte suppl√©mentaire en dehors de YAML.\n\nR√®gles:\n\n-¬†Si l'image repr√©sente un **produit**, renvoyez¬†:\n    \n    ```yaml\n    brand_name¬†: (marque si visible ou d√©ductible)\n    sch√©ma_couleur¬†:\n      - hex¬†: (code hexad√©cimal de chaque couleur importante)\n        nom¬†: (nom descriptif de la couleur)\n    font_style¬†: (serif/sans-serif, gras/fin, etc.)\n    visual_description¬†: (1 √† 2¬†phrases r√©sumant ce qui est vu, en ignorant l'arri√®re-plan)\n    \n    ```\n    \n- Si l'image repr√©sente un **personnage**, renvoyez¬†:\n    \n    ```yaml\n    nom_personnage¬†: (nom s'il est visible ou d√©ductible, sinon \"inconnu\")\n    sch√©ma_couleur¬†:\n      - hex¬†: (code hexad√©cimal de chaque couleur importante sur le caract√®re)\n        nom¬†: (nom descriptif de la couleur)\n    outfit_style¬†: (style vestimentaire, accessoires ou caract√©ristiques notables)\n    visual_description¬†: (1 √† 2 phrases r√©sumant √† quoi ressemble le personnage, en ignorant l'arri√®re-plan)\n    \n    ```\n    \n- Si l'image repr√©sente les **deux**, renvoyez les **deux sections** dans YAML.\n\nNe produisez que du YAML valide. Aucune explication.",
          "modelId": {
            "__rl": true,
            "mode": "list",
            "value": "chatgpt-4o-latest",
            "cachedResultName": "CHATGPT-4O-LATEST"
          },
          "options": {},
          "resource": "image",
          "imageUrls": "=https://api.telegram.org/file/bot{{ $('Set: Bot Token (Placeholder)').first().json.YOUR_BOT_TOKEN }}/{{ $json.result.file_path }}",
          "operation": "analyze"
        },
        "credentials": {
          "openAiApi": {
            "id": "HUbsD20wv3CFr7gN",
            "name": "OpenAi account"
          }
        },
        "typeVersion": 1.8
      },
      {
        "id": "b197982b-4a3d-4a9a-9a04-06ad04f8ef9b",
        "name": "LLM: Structured Output Parser",
        "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
        "position": [
          1824,
          384
        ],
        "parameters": {
          "jsonSchemaExample": "{\n\t\"image_prompt\": \"string\"\n}"
        },
        "typeVersion": 1.3
      },
      {
        "id": "03caf7c5-c03e-4ef7-b104-e7e5a23d0e02",
        "name": "LLM: OpenAI Chat",
        "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
        "position": [
          1600,
          384
        ],
        "parameters": {
          "model": {
            "__rl": true,
            "mode": "list",
            "value": "gpt-4.1-mini"
          },
          "options": {}
        },
        "credentials": {
          "openAiApi": {
            "id": "HUbsD20wv3CFr7gN",
            "name": "OpenAi account"
          }
        },
        "typeVersion": 1.2
      },
      {
        "id": "eaa418ce-bbcd-42d0-ac2a-f7dcda99fdb1",
        "name": "Generate Image Prompt",
        "type": "@n8n/n8n-nodes-langchain.agent",
        "position": [
          1648,
          192
        ],
        "parameters": {
          "text": "=Votre t√¢che consiste √† cr√©er une invite d'image en suivant les directives du syst√®me.  \nAssurez-vous que l'image de r√©f√©rence est repr√©sent√©e de la mani√®re la plus pr√©cise possible**, y compris tous les √©l√©ments de texte.  \n\nUtilisez les entr√©es suivantes¬†:  \n\n- **Description de l'utilisateur¬†:**  \n{{ $('Set¬†: Jeton de bot (Placeholder)').first().json.CAPTION }}\n\n- **Description de l'image de r√©f√©rence¬†:**  \n{{ $json.content }}",
          "options": {
            "systemMessage": "=ROLE: UGC Image Prompt Builder  \n\nGOAL:  \nGenerate one concise, natural, and realistic image prompt (‚â§120 words) from a given product or reference image. The prompt must simulate authentic UGC (user-generated content) photography.  \n\nRULES:  \n- Always output **one JSON object only** with the key:  \n  - `image_prompt`: (string with full description)  \n- Do **not** add commentary, metadata, or extra keys. JSON only.  \n\nSTYLE GUIDELINES:  \n- Tone: casual, unstaged, lifelike, handheld snapshot.  \n- Camera cues: include at least 2‚Äì3 (e.g., phone snapshot, handheld framing, off-center composition, natural indoor light, soft shadows, slight motion blur, auto exposure, unpolished look, mild grain).  \n- Realism: embrace imperfections (wrinkles, stray hairs, skin texture, clutter, smudges).  \n- Packaging/Text: preserve exactly as visible. Never invent claims, numbers, or badges.  \n- Diversity: if people appear but are unspecified, vary gender/ethnicity naturally; default age range = 21‚Äì38.  \n- Setting: default to real-world everyday spaces (home, street, store, gym, office).  \n\nSAFETY:  \n- No copyrighted character names.  \n- No dialogue or scripts. Only describe scenes.  \n\nOUTPUT CONTRACT:  \n- JSON only, no prose outside.  \n- Max 120 words in `image_prompt`.  \n- Must cover: subject, action, mood, setting, style/camera, colors, and text accuracy.  \n\nCHECKLIST BEFORE OUTPUT:  \n- Natural handheld tone?  \n- At least 2 camera cues included?  \n- Product text preserved exactly?  \n- Only JSON returned?  \n\n---  \n\n### Example  \n\nGood Example :  \n```json\n{ \"image_prompt\": \"a young adult casually holding a skincare tube near a bathroom mirror; action: dabs small amount on the back of the hand; mood: easy morning; setting: small apartment bathroom with towel on rack and toothbrush cup; style/camera: phone snapshot, handheld framing, off-center composition, natural window light, slight motion blur, mild grain; colors: soft whites and mint label; text accuracy: keep every word on the tube exactly as visible, no added claims\" }\n"
          },
          "promptType": "define",
          "hasOutputParser": true
        },
        "typeVersion": 2.2
      },
      {
        "id": "04938906-9aa0-49cb-8073-52030f2c7f91",
        "name": "NanoBanana: Create Image",
        "type": "n8n-nodes-base.httpRequest",
        "position": [
          1984,
          192
        ],
        "parameters": {
          "url": "https://queue.fal.run/fal-ai/nano-banana-pro/edit",
          "method": "POST",
          "options": {
            "response": {
              "response": {
                "responseFormat": "json"
              }
            }
          },
          "jsonBody": "={\n  \"prompt\": \"{{ $json.output.image_prompt.replace(/\\\"/g, '\\\\\\\"').replace(/\\n/g, '\\\\n') }}\",\n  \"image_urls\": [\n     \"https://api.telegram.org/file/bot{{ $('Set: Bot Token (Placeholder)').first().json.YOUR_BOT_TOKEN }}/{{ $('Telegram API: Get File URL').first().json.result.file_path }}\"\n  ],\n  \"resolution\": \"1K\",\n  \"aspect_ratio\": \"9:16\",\n  \"output_format\": \"png\"\n}\n",
          "sendBody": true,
          "sendHeaders": true,
          "specifyBody": "json",
          "headerParameters": {
            "parameters": [
              {
                "name": "Content-Type",
                "value": "application/json"
              },
              {
                "name": "Authorization",
                "value": "={{ 'Key ' + $('Set: Bot Token (Placeholder)').first().json.fal_api_key }}"
              }
            ]
          }
        },
        "typeVersion": 4.2
      },
      {
        "id": "526eedfe-fbbd-4aff-bba1-9fbb990a74e4",
        "name": "Wait for Image Edit",
        "type": "n8n-nodes-base.wait",
        "position": [
          2192,
          192
        ],
        "webhookId": "40c00cdc-ee17-499f-9c6e-ca5438d5cfbb",
        "parameters": {
          "amount": 2
        },
        "typeVersion": 1.1
      },
      {
        "id": "51985580-f325-49d3-bfff-83b0de4db6ca",
        "name": "Download Edited Image",
        "type": "n8n-nodes-base.httpRequest",
        "position": [
          2400,
          192
        ],
        "parameters": {
          "url": "={{ $json.response_url }}",
          "options": {}
        },
        "typeVersion": 4.2
      },
      {
        "id": "4534025f-dd17-4225-aaa6-b0343dca4864",
        "name": "Parse GPT Response",
        "type": "n8n-nodes-base.code",
        "position": [
          1360,
          640
        ],
        "parameters": {
          "jsCode": "// Parse responses into { title, prompt, caption, hashtags[], hashtags_string }\nreturn $input.all().map(item => {\n  const data = item.json || {};\n\n  let title = \"\";\n  let prompt = \"\";\n  let caption = \"\";\n  let hashtagsArr = [];\n\n  // 1) NOUVEAU FORMAT : { output: { title, prompt, caption, hashtags } }\n  if (data.output) {\n    const o = data.output || {};\n    title = o.title ?? \"\";\n    prompt = o.prompt ?? \"\";\n    caption = o.caption ?? \"\";\n\n    const rawHashtags = o.hashtags ?? [];\n    if (Array.isArray(rawHashtags)) {\n      hashtagsArr = rawHashtags;\n    } else if (typeof rawHashtags === \"string\") {\n      try {\n        const parsedTags = JSON.parse(rawHashtags);\n        if (Array.isArray(parsedTags)) {\n          hashtagsArr = parsedTags;\n        } else {\n          hashtagsArr = rawHashtags.split(/[,\\s]+/).filter(Boolean);\n        }\n      } catch {\n        hashtagsArr = rawHashtags.split(/[,\\s]+/).filter(Boolean);\n      }\n    }\n  }\n\n  // 2) ANCIEN FORMAT OpenAI (fallback)\n  if (!title && !prompt && !caption && hashtagsArr.length === 0) {\n    let content =\n      data?.choices?.[0]?.message?.content ??\n      data?.message?.content ??\n      data?.content ??\n      null;\n\n    if (content && typeof content === \"object\") {\n      title = content.title ?? \"\";\n      prompt = content.prompt ?? \"\";\n      caption = content.caption ?? \"\";\n\n      if (Array.isArray(content.hashtags)) {\n        hashtagsArr = content.hashtags;\n      } else if (typeof content.hashtags === \"string\") {\n        hashtagsArr = content.hashtags.split(/[,\\s]+/).filter(Boolean);\n      }\n    }\n    else if (typeof content === \"string\" && content.trim()) {\n      try {\n        const parsed = JSON.parse(content);\n        title = parsed.title ?? \"\";\n        prompt = parsed.prompt ?? \"\";\n        caption = parsed.caption ?? \"\";\n\n        if (Array.isArray(parsed.hashtags)) {\n          hashtagsArr = parsed.hashtags;\n        } else if (typeof parsed.hashtags === \"string\") {\n          hashtagsArr = parsed.hashtags.split(/[,\\s]+/).filter(Boolean);\n        }\n      } catch {\n        title = \"\";\n        prompt = \"\";\n        caption = \"\";\n        hashtagsArr = [];\n      }\n    }\n  }\n\n  // 3) Normalisation des hashtags\n  const norm = Array.from(\n    new Set(\n      (hashtagsArr || [])\n        .map(h => (h ?? \"\").toString().trim())\n        .filter(Boolean)\n        .map(h => (h.startsWith(\"#\") ? h : `#${h}`))\n    )\n  );\n\n  const hashtags_string = norm.join(\" \");\n\n  return {\n    json: {\n      title,\n      prompt,\n      caption,\n      hashtags: norm,\n      hashtags_string\n    }\n  };\n});\n"
        },
        "typeVersion": 2
      },
      {
        "id": "1a6f333e-8aa0-4285-bdfb-64b7ca0b6267",
        "name": "Optimize Prompt for Veo",
        "type": "n8n-nodes-base.set",
        "position": [
          1568,
          640
        ],
        "parameters": {
          "options": {},
          "assignments": {
            "assignments": [
              {
                "id": "id-1",
                "name": "veo_prompt",
                "type": "string",
                "value": "={{ $json.prompt }} consistent character throughout, photorealistic quality, professional cinematography, 8 seconds duration, 9:16 aspect ratio, 24fps"
              }
            ]
          },
          "includeOtherFields": true
        },
        "typeVersion": 3.4
      },
      {
        "id": "cfc41241-f73d-4bfc-aa3a-e7d65281bf82",
        "name": "Download Video",
        "type": "n8n-nodes-base.httpRequest",
        "position": [
          2400,
          640
        ],
        "parameters": {
          "url": "={{ $json.video.url }}",
          "options": {
            "response": {
              "response": {
                "responseFormat": "file"
              }
            }
          }
        },
        "typeVersion": 4.2
      },
      {
        "id": "ae4420cd-7088-45a8-942d-c7b96455e685",
        "name": "Prepare Veo Request Body",
        "type": "n8n-nodes-base.code",
        "position": [
          1776,
          640
        ],
        "parameters": {
          "jsCode": "const prompt = $input.item.json.veo_prompt || $input.item.json.prompt;\n\n// Nouvelle source d'image : sortie de \"Download Edited Image\"\nconst imageUrl = $('Download Edited Image').first().json.images[0].url;\n\nif (!prompt || prompt.length < 10) {\n  throw new Error('Prompt required');\n}\n\nif (!imageUrl || typeof imageUrl !== 'string' || !imageUrl.startsWith('http')) {\n  throw new Error('A valid image URL from Download Edited Image is required');\n}\n\n// VEO attend un tableau d'URLs, m√™me si on n'en a qu'une\nconst imageUrls = [imageUrl];\n\nreturn {\n  json: {\n    veo_request_body: {\n      prompt: prompt,\n      image_urls: imageUrls,\n      duration: 8,\n      aspect_ratio: \"9:16\"\n    },\n    ...($input.item.json)\n  }\n};\n"
        },
        "typeVersion": 2
      },
      {
        "id": "50dedf01-6b48-464b-ab9f-3608e499f3cc",
        "name": "Veo Generation",
        "type": "n8n-nodes-base.httpRequest",
        "position": [
          1984,
          640
        ],
        "parameters": {
          "url": "https://fal.run/fal-ai/veo3.1/reference-to-video",
          "method": "POST",
          "options": {
            "timeout": 600000,
            "response": {
              "response": {
                "responseFormat": "json"
              }
            }
          },
          "jsonBody": "={{ JSON.stringify($json.veo_request_body) }}",
          "sendBody": true,
          "sendHeaders": true,
          "specifyBody": "json",
          "headerParameters": {
            "parameters": [
              {
                "name": "Authorization",
                "value": "={{ 'Key ' + $('Set: Bot Token (Placeholder)').first().json.fal_api_key }}"
              },
              {
                "name": "Content-Type",
                "value": "application/json"
              }
            ]
          }
        },
        "typeVersion": 4.2
      },
      {
        "id": "c135569a-c630-4b25-8f6e-2f42b00fb58e",
        "name": "Wait",
        "type": "n8n-nodes-base.wait",
        "position": [
          2192,
          640
        ],
        "webhookId": "d08e597e-4696-4ad6-a068-a774daa84077",
        "parameters": {
          "amount": 2
        },
        "typeVersion": 1.1
      },
      {
        "id": "2a1bc1b1-57d6-483c-a51c-a97675d463c8",
        "name": "Send Video to Telegram",
        "type": "n8n-nodes-base.telegram",
        "position": [
          800,
          1152
        ],
        "webhookId": "f2ebfc81-f6ea-440e-8702-844ab3c6f244",
        "parameters": {
          "chatId": "={{ $('Telegram Trigger: Receive Video Idea').first().json.message.chat.id }}",
          "operation": "sendVideo",
          "binaryData": true,
          "additionalFields": {
            "caption": "=Your video is ready! üé•  {{ $json.video.url }}"
          }
        },
        "credentials": {
          "telegramApi": {
            "id": "TBPespUzbkdn7hk7",
            "name": "Telegram_wan"
          }
        },
        "typeVersion": 1.2
      },
      {
        "id": "6dd2b073-71c5-4d5b-82b2-0383a7e680b7",
        "name": "Step 5 - Publishing",
        "type": "n8n-nodes-base.stickyNote",
        "position": [
          720,
          992
        ],
        "parameters": {
          "color": 5,
          "width": 1852,
          "height": 404,
          "content": "# üìë STEP 3  ‚Äî  Publish with Blotato"
        },
        "typeVersion": 1
      },
      {
        "id": "a984be16-6697-4cfc-bb1c-a8f7463be5a1",
        "name": "Upload Video to BLOTATO",
        "type": "@blotato/n8n-nodes-blotato.blotato",
        "position": [
          1136,
          1152
        ],
        "parameters": {
          "mediaUrl": "={{ $('Download Video').item.json.video.url }}",
          "resource": "media"
        },
        "credentials": {
          "blotatoApi": {
            "id": "wozsYJYLfCZO37j8",
            "name": "Blotato account"
          }
        },
        "typeVersion": 2
      },
      {
        "id": "c3b8258b-5ee7-47fa-9d7e-4e3c59928f9e",
        "name": "Youtube",
        "type": "@blotato/n8n-nodes-blotato.blotato",
        "position": [
          1872,
          1216
        ],
        "parameters": {
          "options": {},
          "platform": "youtube",
          "accountId": {
            "__rl": true,
            "mode": "list",
            "value": "8047",
            "cachedResultUrl": "https://backend.blotato.com/v2/accounts/8047",
            "cachedResultName": "DR FIRASS (Dr. Firas)"
          },
          "postContentText": "={{ $('Parse GPT Response').first().json.caption }}",
          "postContentMediaUrls": "={{ $json.url }}",
          "postCreateYoutubeOptionTitle": "={{ $('Parse GPT Response').first().json.title }}",
          "postCreateYoutubeOptionPrivacyStatus": "private",
          "postCreateYoutubeOptionShouldNotifySubscribers": false
        },
        "credentials": {
          "blotatoApi": {
            "id": "wozsYJYLfCZO37j8",
            "name": "Blotato account"
          }
        },
        "typeVersion": 2
      },
      {
        "id": "981fa66f-f01c-418e-8b02-24865cfb341f",
        "name": "Tiktok",
        "type": "@blotato/n8n-nodes-blotato.blotato",
        "position": [
          1552,
          1056
        ],
        "parameters": {
          "options": {},
          "platform": "tiktok",
          "accountId": {
            "__rl": true,
            "mode": "list",
            "value": "2079",
            "cachedResultUrl": "https://backend.blotato.com/v2/accounts/2079",
            "cachedResultName": "elitecybzcs"
          },
          "postContentText": "={{ $('Parse GPT Response').first().json.caption }}",
          "postContentMediaUrls": "={{ $json.url }}"
        },
        "credentials": {
          "blotatoApi": {
            "id": "wozsYJYLfCZO37j8",
            "name": "Blotato account"
          }
        },
        "typeVersion": 2
      },
      {
        "id": "fa93e28f-6e93-479f-95f3-8d949090fc1c",
        "name": "Linkedin",
        "type": "@blotato/n8n-nodes-blotato.blotato",
        "position": [
          1712,
          1056
        ],
        "parameters": {
          "options": {},
          "platform": "linkedin",
          "accountId": {
            "__rl": true,
            "mode": "list",
            "value": "1446",
            "cachedResultUrl": "https://backend.blotato.com/v2/accounts/1446",
            "cachedResultName": "Samuel Amalric"
          },
          "postContentText": "={{ $('Parse GPT Response').first().json.caption }}",
          "postContentMediaUrls": "={{ $json.url }}"
        },
        "credentials": {
          "blotatoApi": {
            "id": "wozsYJYLfCZO37j8",
            "name": "Blotato account"
          }
        },
        "typeVersion": 2
      },
      {
        "id": "77026e85-e28f-44ff-9ad1-2191565bd8a4",
        "name": "Facebook",
        "type": "@blotato/n8n-nodes-blotato.blotato",
        "position": [
          1872,
          1056
        ],
        "parameters": {
          "options": {},
          "platform": "facebook",
          "accountId": {
            "__rl": true,
            "mode": "list",
            "value": "1759",
            "cachedResultUrl": "https://backend.blotato.com/v2/accounts/1759",
            "cachedResultName": "Firass Ben"
          },
          "facebookPageId": {
            "__rl": true,
            "mode": "list",
            "value": "101603614680195",
            "cachedResultUrl": "https://backend.blotato.com/v2/accounts/1759/subaccounts/101603614680195",
            "cachedResultName": "Dr. Firas"
          },
          "postContentText": "={{ $('Parse GPT Response').first().json.caption }}",
          "postContentMediaUrls": "={{ $json.url }}"
        },
        "credentials": {
          "blotatoApi": {
            "id": "wozsYJYLfCZO37j8",
            "name": "Blotato account"
          }
        },
        "typeVersion": 2
      },
      {
        "id": "87ce0af6-a9e9-47e2-a958-824cb8c52f07",
        "name": "Instagram",
        "type": "@blotato/n8n-nodes-blotato.blotato",
        "position": [
          1552,
          1216
        ],
        "parameters": {
          "options": {},
          "accountId": {
            "__rl": true,
            "mode": "list",
            "value": "1687",
            "cachedResultUrl": "https://backend.blotato.com/v2/accounts/1687",
            "cachedResultName": "acces.a.vie"
          },
          "postContentText": "={{ $('Parse GPT Response').first().json.caption }}",
          "postContentMediaUrls": "={{ $json.url }}"
        },
        "credentials": {
          "blotatoApi": {
            "id": "wozsYJYLfCZO37j8",
            "name": "Blotato account"
          }
        },
        "typeVersion": 2
      },
      {
        "id": "2f7980a6-5d3f-4d2b-a565-4c840529d8c1",
        "name": "Twitter (X)",
        "type": "@blotato/n8n-nodes-blotato.blotato",
        "position": [
          1712,
          1216
        ],
        "parameters": {
          "options": {},
          "platform": "twitter",
          "accountId": {
            "__rl": true,
            "mode": "list",
            "value": "1289",
            "cachedResultUrl": "https://backend.blotato.com/v2/accounts/1289",
            "cachedResultName": "Docteur_Firas"
          },
          "postContentText": "={{ $('Parse GPT Response').first().json.caption }}",
          "postContentMediaUrls": "={{ $json.url }}"
        },
        "credentials": {
          "blotatoApi": {
            "id": "wozsYJYLfCZO37j8",
            "name": "Blotato account"
          }
        },
        "typeVersion": 2
      },
      {
        "id": "eaa3e024-0eef-4a71-ae0b-25fe1cc27a1c",
        "name": "Merge1",
        "type": "n8n-nodes-base.merge",
        "position": [
          2144,
          1072
        ],
        "parameters": {
          "mode": "chooseBranch",
          "numberInputs": 6
        },
        "typeVersion": 3.2
      },
      {
        "id": "4889de2f-81e3-49e2-a921-739aec5be20e",
        "name": "Send a text message",
        "type": "n8n-nodes-base.telegram",
        "position": [
          2368,
          1136
        ],
        "webhookId": "ba74ea20-4e1f-45e4-b95e-0c41b4394b56",
        "parameters": {
          "text": "Publi√©",
          "chatId": "={{ $('Telegram Trigger: Receive Video Idea').first().json.message.chat.id }}",
          "additionalFields": {}
        },
        "credentials": {
          "telegramApi": {
            "id": "TBPespUzbkdn7hk7",
            "name": "Telegram_wan"
          }
        },
        "typeVersion": 1.2
      },
      {
        "id": "3e6b4da3-2e64-49f4-8e76-97753b87b81b",
        "name": "Sticky Note5",
        "type": "n8n-nodes-base.stickyNote",
        "position": [
          48,
          96
        ],
        "parameters": {
          "width": 652,
          "height": 1300,
          "content": "# üöÄ AI Viral Video Workflow ‚Äî NanoBanana 2 PRO √ó VEO3.1 √ó Blotato (By Dr. Firas)\n\n[![AI Voice Agent Preview](https://www.dr-firas.com/nanobanana2.png)](https://youtu.be/nlwpbXQqNQ4)\n\n##  üìò Documentation  \nAccess detailed setup instructions, API config, platform connection guides, and workflow customization tips:\n\nüìé [Open the full documentation on Notion](https://automatisation.notion.site/NonoBanan-PRO-2-2b53d6550fd981a5acbecf7cf50aeb3c?source=copy_link)\n\nThis workflow converts a simple Telegram message into a **ready-to-publish AI viral video**, fully automated.\n\n## üî• What this workflow does\n### 1Ô∏è‚É£ Image Creation (NanoBanana 2 PRO)\n- User sends on Telegram:\n  - A reference image  \n  - A short text idea  \n### 2Ô∏è‚É£ Video Generation (VEO3.1)\n- An AI Agent builds a structured video prompt  \n- Optimizes it for **VEO3.1**  \n- Generates a vertical 9:16 video (8 seconds)  \n- Sends the final video to Telegram\n### 3Ô∏è‚É£ Multi-Platform Publishing (Blotato)\n- Uploads the video to Blotato  \n- Auto-publishes to\n\n## ‚öôÔ∏è Requirements\n1. ‚úÖ **Create a [Blotato](https://blotato.com/?ref=firas) account** (Pro plan required for API access)  \n2. üîë **Generate your Blotato API Key** via: `Settings > API > Generate API Key`  \n3. üì¶ **Enable ‚ÄúVerified Community Nodes‚Äù** in the n8n admin settings  \n4. üß© **Install the Blotato** verified community node in n8n  \n5. üõ† **Create a Blotato API credential** inside your n8n credentials tab  "
        },
        "typeVersion": 1
      }
    ],
    "active": false,
    "pinData": {},
    "settings": {
      "executionOrder": "v1"
    },
    "versionId": "6eeaa654-b434-47fa-b135-e915b506d7c7",
    "connections": {
      "Wait": {
        "main": [
          [
            {
              "node": "Download Video",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Think": {
        "ai_tool": [
          [
            {
              "node": "AI Agent: Generate Video Script",
              "type": "ai_tool",
              "index": 0
            }
          ]
        ]
      },
      "Merge1": {
        "main": [
          [
            {
              "node": "Send a text message",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Tiktok": {
        "main": [
          [
            {
              "node": "Merge1",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Youtube": {
        "main": [
          [
            {
              "node": "Merge1",
              "type": "main",
              "index": 5
            }
          ]
        ]
      },
      "Facebook": {
        "main": [
          [
            {
              "node": "Merge1",
              "type": "main",
              "index": 2
            }
          ]
        ]
      },
      "Linkedin": {
        "main": [
          [
            {
              "node": "Merge1",
              "type": "main",
              "index": 1
            }
          ]
        ]
      },
      "Instagram": {
        "main": [
          [
            {
              "node": "Merge1",
              "type": "main",
              "index": 3
            }
          ]
        ]
      },
      "Twitter (X)": {
        "main": [
          [
            {
              "node": "Merge1",
              "type": "main",
              "index": 4
            }
          ]
        ]
      },
      "Download Video": {
        "main": [
          [
            {
              "node": "Send Video to Telegram",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Veo Generation": {
        "main": [
          [
            {
              "node": "Wait",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "LLM: OpenAI Chat": {
        "ai_languageModel": [
          [
            {
              "node": "Generate Image Prompt",
              "type": "ai_languageModel",
              "index": 0
            }
          ]
        ]
      },
      "OpenAI Chat Model": {
        "ai_languageModel": [
          [
            {
              "node": "AI Agent: Generate Video Script",
              "type": "ai_languageModel",
              "index": 0
            }
          ]
        ]
      },
      "Set Master Prompt": {
        "main": [
          [
            {
              "node": "AI Agent: Generate Video Script",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Parse GPT Response": {
        "main": [
          [
            {
              "node": "Optimize Prompt for Veo",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Wait for Image Edit": {
        "main": [
          [
            {
              "node": "Download Edited Image",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Download Edited Image": {
        "main": [
          [
            {
              "node": "Set Master Prompt",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Generate Image Prompt": {
        "main": [
          [
            {
              "node": "NanoBanana: Create Image",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Send Video to Telegram": {
        "main": [
          [
            {
              "node": "Upload Video to BLOTATO",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Optimize Prompt for Veo": {
        "main": [
          [
            {
              "node": "Prepare Veo Request Body",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Upload Video to BLOTATO": {
        "main": [
          [
            {
              "node": "Tiktok",
              "type": "main",
              "index": 0
            },
            {
              "node": "Linkedin",
              "type": "main",
              "index": 0
            },
            {
              "node": "Facebook",
              "type": "main",
              "index": 0
            },
            {
              "node": "Instagram",
              "type": "main",
              "index": 0
            },
            {
              "node": "Twitter (X)",
              "type": "main",
              "index": 0
            },
            {
              "node": "Youtube",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "NanoBanana: Create Image": {
        "main": [
          [
            {
              "node": "Wait for Image Edit",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Prepare Veo Request Body": {
        "main": [
          [
            {
              "node": "Veo Generation",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Structured Output Parser": {
        "ai_outputParser": [
          [
            {
              "node": "AI Agent: Generate Video Script",
              "type": "ai_outputParser",
              "index": 0
            }
          ]
        ]
      },
      "Telegram API: Get File URL": {
        "main": [
          [
            {
              "node": "OpenAI Vision: Analyze Reference Image",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Set: Bot Token (Placeholder)": {
        "main": [
          [
            {
              "node": "Telegram API: Get File URL",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "LLM: Structured Output Parser": {
        "ai_outputParser": [
          [
            {
              "node": "Generate Image Prompt",
              "type": "ai_outputParser",
              "index": 0
            }
          ]
        ]
      },
      "AI Agent: Generate Video Script": {
        "main": [
          [
            {
              "node": "Parse GPT Response",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Telegram Trigger: Receive Video Idea": {
        "main": [
          [
            {
              "node": "Set: Bot Token (Placeholder)",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "OpenAI Vision: Analyze Reference Image": {
        "main": [
          [
            {
              "node": "Generate Image Prompt",
              "type": "main",
              "index": 0
            }
          ]
        ]
      }
    }
  }
}